{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "* Key concept to Bayesian stats is Bayes' theorem\n",
    "* This can be derived easily if conditional probability is understood\n",
    "* Probability is value between 0 and 1 that represents degree of belief in a prediction.\n",
    "* Conditional probability is a probability based on background information.\n",
    "* P(A|B) is the probability that A occurs given that B has occured.\n",
    "* Conjoint probability is the probability that two things are true, P(A and B)\n",
    "* For independent events only, P(A and B) = P(A)P(B). Doesn't hold for events with dependencies.\n",
    "* For independent events, chance that B occurs doesn't change whether or not A has occurred: P(B|A) = P(B) (in this case)\n",
    "* In genral, probability of conjunction: P(A and B) = P(A|B)P(B) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cookie problem\n",
    "\n",
    "Two bowls of cookies. Bowl A has 30 plain and 10 chocolate, Bowl B has 20 of each.\n",
    "\n",
    "Suppose you choose a bowl at random and take a cookie which is plain. What is the probability that you chose bowl A?\n",
    "\n",
    "Conditional probability: P(Bowl A | plain)\n",
    "\n",
    "It's not obvious how to compute. However, it would be easy to answer P(plain | bowl A) = 3/4\n",
    "\n",
    "The two conditional probabilities are not the same but we can use bayes theorem to go from one to the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes' theorem\n",
    "\n",
    "* Conjuction is commutative: P(A and B) = P(B and A)\n",
    "\n",
    "* P(A and B) = P(A|B)P(B) and P(B and A) = P(B|A)P(A)\n",
    "\n",
    "* P(A|B)P(B) = P(B|A)P(A)\n",
    "\n",
    "* Which can be written: P(A|B) = P(B|A)P(A) / P(B) (Bayes!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solving the cookie problem\n",
    "\n",
    "* P(bowl A | plain) = P(plain | bowl A) P(bowl A) / P(plain)\n",
    "\n",
    "* P(plain | bowl A) = 0.75\n",
    "\n",
    "* P(bowl A) = 0.5\n",
    "\n",
    "* P(plain) = (30 + 20) / (30 + 10 + 20 + 20) = 5/8\n",
    "\n",
    "* So, P(bowl A | plain) = (0.75 * 0.5) / 0.625 = 0.6 = 3/5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The diachronic interpretation\n",
    "\n",
    "* Diachronic means something is happening over time, we can use Bayes to see how our hypothesis changes over time given new data.\n",
    "\n",
    "* We can rewrite the theorem for our hypothesis, H, and the data, D, as:\n",
    "\n",
    "P(H|D) = P(H) P(D|H) / P(D)\n",
    "\n",
    "* P(H) is the probability of the hypothesis before we see the data, or the *prior*\n",
    "* P(H|D) is the probability of the hypothesis after we see the data, or the *posterior* (what we want to compute)\n",
    "* P(D|H) is the probability of the data under the hypothesis, or the *likelihood*\n",
    "* P(D) is the probability of the data under any hypothesis, or the *normalising constant*\n",
    "\n",
    "*\"Today's posterior is tomorrows prior\"* - https://jimgrange.wordpress.com/2016/01/18/pesky-priors/\n",
    "\n",
    "* Prior can sometimes be computed using background information, otherwise can be subjective (people might disagree).\n",
    "* Likelihood is often easy to compute, based on population statistics.\n",
    "* Normlising constant can be tricky...\n",
    "\n",
    "* Set (or suite) of hypotheses must be:\n",
    "    * Mutually exclusive: only one hypothesis (max) can be true\n",
    "    * Collectively exhaustive: out of all options, one must be true\n",
    "    \n",
    "* P(D) can be computed using the law of total probability: if two (or more) exclusive ways something could happen, you can add up the probabilities like this:\n",
    "P(D) = P(bowl 1) P(D|bowl 1) + p(bowl 2) p(D|bowl 2)\n",
    "\n",
    "* This gives 1/2 * 3/4 + 1/2 * 1/2 = 5/8 (as we had before)\n",
    "* Law of total probability: https://www.statology.org/law-of-total-probability/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The M&M problem\n",
    "\n",
    "* Old M&M's: Brown 0.3, Yellow 0.2, Red 0.2 Green 0.1, Orange 0.1 and Tan 0.1.\n",
    "* New M&M's: Blue 0.24, Brown 0.13, Yellow 0.13, Red 0.13, Green 0.2 and Orange 0.16.\n",
    "\n",
    "* Two bags, one is old and one is new. One M&M from each bag, yellow and green. What is probability that yellow M&M came from old bag?\n",
    "\n",
    "* We can use the table method to solve this.\n",
    "* First we state our hypotheses:\n",
    "    * Hyp A: Bag 1 is old, bag 2 is new\n",
    "    * Hyp B: Bag 1 is new, bag 2 is old\n",
    "\n",
    "|      .          | Prior P(H)     | Likelihood P(D\\|H)    |P(H)P(D\\|H)    | Posterior P(H\\|D)    |\n",
    "| :------------- | :----------: | :----------: |:----------: | -----------: |\n",
    "| A| 1/2   | (20)(20) |200   | 20/27   |\n",
    "| B | 1/2 | (10)(14) |70 | 7/27 |\n",
    "\n",
    "* Priors are set at 50% for each.\n",
    "* Likelihood is written as percentage not probabilities, so will be out by factor of 10,000 but this accounted for by the normalising constant.\n",
    "* P(H)P(D|H) is the sum of the prior and likelihood.\n",
    "* Normalising constant is the sum of the P(H)P(D|H) column, in this case 200 + 70 = 270."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monty Hall problem\n",
    "\n",
    "* The monty hall problem is a counter intuitive probability scenario.\n",
    "* 3 closed doors. A car behind one door and less valuable prizes behind the other two. Need to guess which door has the car.\n",
    "* You choose door A. Then door B or C will be opened to reveal a lesser prize. You have the choice to stick with door A or switch to the other remaining closed door. In this case, door B is opened.\n",
    "* Seems that it would make no difference, but in actual fact you should switch to win (2/3 chance of win vs 1/3).\n",
    "* We can break this down into 3 hypotheses about which door has the car, A, B or C.\n",
    "\n",
    "\n",
    "|      .          | Prior P(H)     | Likelihood P(D\\|H)    |P(H)P(D\\|H)    | Posterior P(H\\|D)    |\n",
    "| :------------- | :----------: | :----------: |:----------: | -----------: |\n",
    "| A| 1/3   | 1/2 | 1/6   | 1/3   |\n",
    "| B | 1/3 | 0 |0 | 0 |\n",
    "| C | 1/3 | 1 |1/3 | 2/3 |\n",
    "\n",
    "* Priors are straigth forward as prizes are randomised.\n",
    "* Likelihoods trickier, if car is behind A then probability that he opens B is 1/2.\n",
    "* If car is behind B, he can't open B so chance it's opened is 0.\n",
    "* If car is behing C, he has to open B otherwise he would reveal the car, so opening B has prob 1.\n",
    "\n",
    "* Note, there is another variation where door B will always be opened if possible, and C will only be opened if it's behind B. In this case the table looks like this:\n",
    "\n",
    "|      .          | Prior P(H)     | Likelihood P(D\\|H)    |P(H)P(D\\|H)    | Posterior P(H\\|D)    |\n",
    "| :------------- | :----------: | :----------: |:----------: | -----------: |\n",
    "| A| 1/3   | 1 | 1/3   | 1/2   |\n",
    "| B | 1/3 | 0 |0 | 0 |\n",
    "| C | 1/3 | 1 |1/3 | 1/2 |\n",
    "\n",
    "* So this small difference actually leads to the loss of an effect of switching doors (as door B being chosen reveals no information about the location of the car). Note, this only works if the labels (A,B and C) are private and not known to host and the player.\n",
    "\n",
    "* Other Bayes problems can be found here: https://allendowney.blogspot.com/2011/10/all-your-bayes-are-belong-to-us.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
